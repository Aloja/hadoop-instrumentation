Importar branch "smendoza" del repo hadoop-extrae (http://vbqvm.pc.ac.upc.edu/redmine/projects/hadoopextrae/repository), té els últims canvis que va fer el sergio.

Mirar el codi que hi ha a minerva-1:/scratch/hdd/yolandab/lightness en diferents arxius comprimits, tindria que ser el mateix que hi ha a la branch anterior.

Incorporar els canvis de la branch "master" del repo hadoop-extrae (fent un rebase o un diff entre branches), ja que conté millores en la reorganització del projecte fetes pel David i el Nico (la branch npoggi ja està integrada a master).

L'objectiu es tenir una màquina Vagrant dins d'un folder d'aquest repo que pugui aixecar un Hadoop ja configurat i llest per executar jobs amb el "extrae" afagant les mètriques.

En el dropbox està la documentació a instrumentation/README_v4.docx 

Projecte amb un Vagrant de referència: https://github.com/servioticy/servioticy-vagrant

Extrae i paraver disponible a: http://www.bsc.es/computer-sciences/performance-tools/downloads


PARAVER (wxparaver)

load traces -> dades (.prv)
load conf .cfg -> vista concreta (amb filtres, etc...)
.pcf -> events, codis d'events i semantiques
.row -> igual que l'anterior pero dels threads


COMPILE EXTRAEWRAPPER.JAR
-------------------------
# Necessita java7 per compilar
sudo update-alternatives --config java

mkdir -p hadoop-src
tar xf deps/hadoop-1.0.3.tar.gz --strip-components=1 -C hadoop-src

mkdir -p deps/binutils
tar xf deps/binutils-2.23.tar.gz --strip-components=1 -C deps/binutils

( cd deps/binutils/bfd/ ; ./configure --prefix=/vagrant/workspace/local/ --enable-shared=yes )
make -C deps/binutils/bfd/
make -C deps/binutils/bfd/ install

# https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=530888
( cd deps/binutils/libiberty/ ; CFLAGS=-fPIC ./configure --prefix=/vagrant/workspace/local/ )
make -C deps/binutils/libiberty/
make -C deps/binutils/libiberty/ install

mkdir -p deps/extrae
tar xf deps/extrae-2.5.1.tar --strip-components=1 -C deps/extrae
( cd deps/extrae/ ; ./configure --without-mpi --without-unwind --without-dyninst --without-papi --with-binutils=/vagrant/workspace/local --prefix=/vagrant/workspace/local/ )
make -C deps/extrae/
make -C deps/extrae/ install

mkdir -p deps/libpcap
tar xf deps/libpcap-1.4.0.tar.gz --strip-components=1 -C deps/libpcap

make -C extrae/java_wrapper/


COMPILE HADOOP
--------------
# Necessita java6 per compilar, a partir de la versio v1.1.0 ja es pot compilar amb java7
sudo update-alternatives --config java

mkdir -p hadoop-src
tar xf deps/hadoop-1.0.3.tar.gz --strip-components=1 -C hadoop-src

patch --directory=hadoop-src --forward --reject-file=- -p1 < hadoop-src-changes.patch
patch --directory=hadoop-src --forward --reject-file=- -p1 < hadoop_vanilla_to_compile.patch

sed -i'' 's|<target name="package" depends="compile, jar, javadoc, docs, cn-docs, api-report, examples, tools-jar, jar-test, ant-tasks, package-librecordio"|<target name="package" depends="compile, jar, javadoc, api-report, examples, tools-jar, jar-test, ant-tasks, package-librecordio"|' hadoop-src/build.xml

ln -s -f ../../local/lib/extraewrapper.jar hadoop-src/lib/extraewrapper.jar

ant -buildfile hadoop-src/build.xml -Ddist.dir='/vagrant/workspace/hadoop-build' -Dskip.compile-mapred-classes=true package
# WARNING: change absolute path (/vagrant/workspace/hadoop-build) with BASE_DIR when creating definitive script
# (the alternative "ant binary" does not copy all files inside build dir, for example /conf)
# (the original command found was "ant -Dskip.contrib=true -Dskip.compile-mapred-classes=true package")


RUN
---
# Necessita java7 per executar
sudo update-alternatives --config java

echo "localhost" > hadoop-build/conf/masters && echo "localhost" > hadoop-build/conf/slaves

sed -i'' 's@# export JAVA_HOME=/usr/lib/j2sdk1.5-sun@export JAVA_HOME=$(readlink -f /usr/bin/java | sed "s:/bin/java::" | sed "s:/jre::")\n\nexport HADOOP_EXTRAE_LIBRARY_PATH="/vagrant/workspace/local/lib"\n\nexport EXTRAE_ON=1\nexport EXTRAE_DIR=/tmp\nexport EXTRAE_HOME=/vagrant/workspace/local@' hadoop-build/conf/hadoop-env.sh
sed -i'' 's|<configuration>|<configuration>\n\n<property>\n<name>fs.default.name</name>\n<value>hdfs://localhost:50000</value>\n</property>|' hadoop-build/conf/core-site.xml
sed -i'' 's|<configuration>|<configuration>\n\n<property>\n<name>mapred.job.tracker</name>\n<value>localhost:50001</value>\n</property>\n<property>\n<name>mapred.tasktracker.map.tasks.maximum</name>\n<value>2</value>\n</property>\n<property>\n<name>mapred.tasktracker.reduce.tasks.maximum</name>\n<value>2</value>\n</property>|' hadoop-build/conf/mapred-site.xml
sed -i'' 's|<configuration>|<configuration>\n\n<property>\n<name>dfs.replication</name>\n<value>1</value>\n</property>|' hadoop-build/conf/hdfs-site.xml


./hadoop-build/bin/hadoop namenode -format
./hadoop-build/bin/start-all.sh
./hadoop-build/bin/stop-all.sh



Error extraewrapper.jar precompilat, solucio: la configuracio de hadoop era incompleta (faltaven settings per posar)
2014-11-18 14:14:03,166 FATAL org.apache.hadoop.mapred.JobTracker: java.lang.ArrayIndexOutOfBoundsException: 1
        at es.bsc.tools.extrae.IDManager.digestConfiguration(IDManager.java:342)
        at es.bsc.tools.extrae.IDManager.registerJobTracker(IDManager.java:155)
        at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:291)
        at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4983)


Error falta llibreria seqtrace:
2014-11-18 14:47:32,336 FATAL org.apache.hadoop.mapred.JobTracker: java.lang.UnsatisfiedLinkError: no seqtrace in java.library.path
        at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1886)
        at java.lang.Runtime.loadLibrary0(Runtime.java:849)
        at java.lang.System.loadLibrary(System.java:1088)
        at es.bsc.tools.extrae.Wrapper.<clinit>(Wrapper.java:10)
        at es.bsc.tools.extrae.IDManager.digestConfiguration(IDManager.java:413)
        at es.bsc.tools.extrae.IDManager.registerJobTracker(IDManager.java:155)
        at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:291)
        at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4983)





POST-PROCESS
------------
Aquest codi estava al final del run.sh en el backup del home del sergio:

#Post-procesado aquíi tiempo que me ahorro
bash post-process-dumpingd.sh 
bash post-process-extrae-traces.sh 
bash post-process-undef2prv.sh 



HADOOP BUGS
-----------
ant target without source and docs
https://issues.apache.org/jira/browse/HADOOP-2298

make it possible to build hadoop tarballs without java5+ forrest
https://issues.apache.org/jira/browse/HADOOP-8916

Build fails with Java 7
https://issues.apache.org/jira/browse/HADOOP-8329
