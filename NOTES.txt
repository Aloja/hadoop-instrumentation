Importar branch "smendoza" del repo hadoop-extrae (http://vbqvm.pc.ac.upc.edu/redmine/projects/hadoopextrae/repository), té els últims canvis que va fer el sergio.

Mirar el codi que hi ha a minerva-1:/scratch/hdd/yolandab/lightness en diferents arxius comprimits, tindria que ser el mateix que hi ha a la branch anterior.

Incorporar els canvis de la branch "master" del repo hadoop-extrae (fent un rebase o un diff entre branches), ja que conté millores en la reorganització del projecte fetes pel David i el Nico (la branch npoggi ja està integrada a master).

L'objectiu es tenir una màquina Vagrant dins d'un folder d'aquest repo que pugui aixecar un Hadoop ja configurat i llest per executar jobs amb el "extrae" afagant les mètriques.

En el dropbox està la documentació a instrumentation/README_v4.docx 

Projecte amb un Vagrant de referència: https://github.com/servioticy/servioticy-vagrant

Extrae i paraver disponible a: http://www.bsc.es/computer-sciences/performance-tools/downloads


PARAVER (wxparaver)

load traces -> dades (.prv)
load conf .cfg -> vista concreta (amb filtres, etc...)
.pcf -> events, codis d'events i semantiques
.row -> igual que l'anterior pero dels threads


COMPILE EXTRAEWRAPPER.JAR
-------------------------
# Necessita java7 per compilar
sudo update-alternatives --config java

mkdir -p hadoop-src
tar xf deps/hadoop-1.0.3.tar.gz --strip-components=1 -C hadoop-src

mkdir -p deps/binutils
tar xf deps/binutils-2.23.tar.gz --strip-components=1 -C deps/binutils

( cd deps/binutils/bfd/ ; ./configure --prefix=/vagrant/workspace/local/ --enable-shared=yes )
make -C deps/binutils/bfd/
make -C deps/binutils/bfd/ install

# https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=530888
( cd deps/binutils/libiberty/ ; CFLAGS=-fPIC ./configure --prefix=/vagrant/workspace/local/ )
make -C deps/binutils/libiberty/
make -C deps/binutils/libiberty/ install

mkdir -p deps/extrae
tar xf deps/extrae-2.5.1.tar --strip-components=1 -C deps/extrae
( cd deps/extrae/ ; ./configure --without-mpi --without-unwind --without-dyninst --without-papi --with-binutils=/vagrant/workspace/local --prefix=/vagrant/workspace/local/ )
make -C deps/extrae/
make -C deps/extrae/ install

mkdir -p deps/libpcap
tar xf deps/libpcap-1.4.0.tar.gz --strip-components=1 -C deps/libpcap

make -C extrae/java_wrapper/


COMPILE HADOOP
--------------
# Necessita java6 per compilar, a partir de la versio v1.1.0 ja es pot compilar amb java7
sudo update-alternatives --config java

mkdir -p hadoop-src
tar xf deps/hadoop-1.0.3.tar.gz --strip-components=1 -C hadoop-src

patch --directory=hadoop-src --forward --reject-file=- -p1 < hadoop-src-changes.patch
patch --directory=hadoop-src --forward --reject-file=- -p1 < hadoop_vanilla_to_compile.patch

sed -i'' 's|<target name="package" depends="compile, jar, javadoc, docs, cn-docs, api-report, examples, tools-jar, jar-test, ant-tasks, package-librecordio"|<target name="package" depends="compile, jar, javadoc, api-report, examples, tools-jar, jar-test, ant-tasks, package-librecordio"|' hadoop-src/build.xml

ant -buildfile hadoop-src/build.xml -Ddist.dir='/vagrant/workspace/hadoop-build' -Dskip.compile-mapred-classes=true package
# WARNING: change absolute path (/vagrant/workspace/hadoop-build) with BASE_DIR when creating definitive script
# (the alternative "ant binary" does not copy all files inside build dir, for example /conf)
# (the original command found was "ant -Dskip.contrib=true -Dskip.compile-mapred-classes=true package")


RUN
---
# Clean: rm -rf /vagrant/workspace/hadoop-build/logs/* /tmp/hadoop-vagrant* /tmp/smendoza/ /tmp/smfile
# Necessita java7 per executar
sudo update-alternatives --config java

cp config/hadoop-conf/* hadoop-build/conf/
echo "`hostname`" > hadoop-build/conf/masters && echo "`hostname`" > hadoop-build/conf/slaves

./hadoop-build/bin/hadoop namenode -format
./hadoop-build/bin/start-all.sh
./hadoop-build/bin/stop-all.sh



Error extraewrapper.jar precompilat, solucio: la configuracio de hadoop era incompleta (faltaven settings per posar)
2014-11-18 14:14:03,166 FATAL org.apache.hadoop.mapred.JobTracker: java.lang.ArrayIndexOutOfBoundsException: 1
        at es.bsc.tools.extrae.IDManager.digestConfiguration(IDManager.java:342)
        at es.bsc.tools.extrae.IDManager.registerJobTracker(IDManager.java:155)
        at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:291)
        at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4983)


Error falta llibreria seqtrace:
2014-11-18 14:47:32,336 FATAL org.apache.hadoop.mapred.JobTracker: java.lang.UnsatisfiedLinkError: no seqtrace in java.library.path
        at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1886)
        at java.lang.Runtime.loadLibrary0(Runtime.java:849)
        at java.lang.System.loadLibrary(System.java:1088)
        at es.bsc.tools.extrae.Wrapper.<clinit>(Wrapper.java:10)
        at es.bsc.tools.extrae.IDManager.digestConfiguration(IDManager.java:413)
        at es.bsc.tools.extrae.IDManager.registerJobTracker(IDManager.java:155)
        at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:291)
        at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4983)





POST-PROCESS
------------
Aquest codi estava al final del run.sh en el backup del home del sergio:

#Post-procesado aquíi tiempo que me ahorro
bash post-process-dumpingd.sh 
bash post-process-extrae-traces.sh 
bash post-process-undef2prv.sh 


El post-process-dumpingd.sh parseja tots els logs dels ports utilitzats en totes les maquines, i unifica el output resultant a $TMP_PPING/distributed-merge/dumping-host-port-pid

El post-process-extrae-traces.sh parseja tots els arxius del extrae $TMP_PPING/set-* i $TMP_PPING/TRACE.mpits i unifica el output resultant a $TMP_PPING/distributed-merge/TRACE.mpits per despres utilitzar el mpi2prv per generar els arxius $TMP_PPING/mergeoutput.prv $TMP_PPING/mergeoutput.pcf $TMP_PPING/mergeoutput.row

El post-process-undef2prv.sh parseja els arxius $TMP_PPING/distributed-merge/dumping-host-port-pid (generat per post-process-dumpingd.sh) $TMP_PPING/mergeoutput.prv $TMP_PPING/mergeoutput.row



SYNCHRONIZATION WITH MULTIPLE NODES
-----------------------------------
Inicialment el mpi2prv tenia el parametre -syn, i com que al principi les proves es feien en un unic node les traces no tenien sentit. Al treure-ho es va comprovar que els diferents processos quedaven sincronitzats correctament. Al passar a executar multiples nodes, es va tornar a veure que les traces no tenien sentit, ja que si no s'especifica res al mpi2prv, aquest detecta en quants nodes s'ha executat la instrumentació i activa o desactiva la sincronització automaticament. Es pot veure com a http://compss.bsc.es/svn/releases/compss/latest/files/extrae/ChangeLog surt aquest comentari: "-syn is automatically set to on/off depending on the nodes where the instrumented application ran".

Intentat canviar el TSC de les maquines virtuals del virtualbox (https://www.virtualbox.org/manual/ch09.html#changetscmode), pero no ha funcionat.

Treure low power de les CPU, per evitar que canvii els MHz. Provar primer al portatil del bsc, i si no funciona intentar-ho a minerva.

El comptador "rdtsc" comença desde 0 al inici del sistema. Quan es fan execucions amb multiples maquines virtuals mitjançant vagrant, l'ordre i el delay entre l'arrancada d'aquestes significa que les traces estan desplaçades. Hi ha dues possibles solucions. Es pot agafar un punt de referencia de cada node, per exemple el moment d'inici del daemon DataNode, ja que s'inicien consecutivament al principi (potser hi ha una mica de delay ja que s'inicien sequencialment de forma síncrona, però pot ser prou bo). Una alternativa pot ser crear un event nou que tingui com a valor el unix timestamp actual (amb la màxima precisió), ja que d'aquesta forma per a cada node hi haurà una relació entre el unix timestamp i el rdtsc, i es pot moure tots els events per normalitzar-ho.



DIAGNOSTIC
----------
Nomes han de sortir processos map
grep ":33333:" mergeoutput.prv | cut -d: -f -5 | sort -u
grep ":44444:" mergeoutput.prv | cut -d: -f -5 | sort -u
grep ":11112:8:" mergeoutput.prv | cut -d: -f -5 | sort -u

grep ":33333:" mergeoutput-out.prv | cut -d: -f -5 | sort -u
grep ":44444:" mergeoutput-out.prv | cut -d: -f -5 | sort -u
grep ":11112:8:" mergeoutput-out.prv | cut -d: -f -5 | sort -u

Nomes han de sortir processos reduce
grep ":11112:9:" mergeoutput.prv | cut -d: -f -5 | sort -u
grep ":11112:10:" mergeoutput.prv | cut -d: -f -5 | sort -u
grep ":11112:11:" mergeoutput.prv | cut -d: -f -5 | sort -u
grep ":11112:12:" mergeoutput.prv | cut -d: -f -5 | sort -u

grep ":11112:9:" mergeoutput-out.prv | cut -d: -f -5 | sort -u
grep ":11112:10:" mergeoutput-out.prv | cut -d: -f -5 | sort -u
grep ":11112:11:" mergeoutput-out.prv | cut -d: -f -5 | sort -u
grep ":11112:12:" mergeoutput-out.prv | cut -d: -f -5 | sort -u



COSES PER FER DEL POST-PROCESS
------------------------------

El post-process-dumpingd.sh fa un grep de WALA en els logs de hadoop que no retorna cap resultat. Revisar a quines parts del codi es fa prints de WALA i veure si s'executen.

El post-process-undef2prv.sh peta al no trobar l'arxiu /tmp/smendoza/jc.pid pero aquest no apareix referenciat a cap mes lloc del repositori. Potser significa JobClient?

java.io.FileNotFoundException: /tmp/smendoza/jc.pid (No such file or directory)
        at java.io.FileInputStream.open(Native Method)
        at java.io.FileInputStream.<init>(FileInputStream.java:146)
        at java.io.FileInputStream.<init>(FileInputStream.java:101)
        at java.io.FileReader.<init>(FileReader.java:58)
        at es.bsc.tools.undef2prv.DataOnMemory.loadJClient(DataOnMemory.java:401)
        at es.bsc.tools.undef2prv.Undef2prv.main(Undef2prv.java:39)




HADOOP BUGS
-----------
ant target without source and docs
https://issues.apache.org/jira/browse/HADOOP-2298

make it possible to build hadoop tarballs without java5+ forrest
https://issues.apache.org/jira/browse/HADOOP-8916

Build fails with Java 7
https://issues.apache.org/jira/browse/HADOOP-8329
