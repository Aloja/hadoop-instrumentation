diff -uNr extrae-2.3.4-vanilla/PREFIX extrae-2.3.4-hadoop/PREFIX
--- extrae-2.3.4-vanilla/PREFIX	1970-01-01 01:00:00.000000000 +0100
+++ extrae-2.3.4-hadoop/PREFIX	2013-09-09 00:57:10.596639052 +0200
@@ -0,0 +1 @@
+/home/dcarrera/MS/extrae/dist
diff -uNr extrae-2.3.4-vanilla/src/merger/common/hadoop_merge.c extrae-2.3.4-hadoop/src/merger/common/hadoop_merge.c
--- extrae-2.3.4-vanilla/src/merger/common/hadoop_merge.c	1970-01-01 01:00:00.000000000 +0100
+++ extrae-2.3.4-hadoop/src/merger/common/hadoop_merge.c	2013-09-09 00:43:45.666816093 +0200
@@ -0,0 +1,193 @@
+/*****************************************************************************\
+ *                        ANALYSIS PERFORMANCE TOOLS                         *
+ *                                   Extrae                                  *
+ *              Instrumentation package for parallel applications            *
+ *****************************************************************************
+ *     ___     This library is free software; you can redistribute it and/or *
+ *    /  __         modify it under the terms of the GNU LGPL as published   *
+ *   /  /  _____    by the Free Software Foundation; either version 2.1      *
+ *  /  /  /     \   of the License, or (at your option) any later version.   *
+ * (  (  ( B S C )                                                           *
+ *  \  \  \_____/   This library is distributed in hope that it will be      *
+ *   \  \__         useful but WITHOUT ANY WARRANTY; without even the        *
+ *    \___          implied warranty of MERCHANTABILITY or FITNESS FOR A     *
+ *                  PARTICULAR PURPOSE. See the GNU LGPL for more details.   *
+ *                                                                           *
+ * You should have received a copy of the GNU Lesser General Public License  *
+ * along with this library; if not, write to the Free Software Foundation,   *
+ * Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA          *
+ * The GNU LEsser General Public License is contained in the file COPYING.   *
+ *                                 ---------                                 *
+ *   Barcelona Supercomputing Center - Centro Nacional de Supercomputacion   *
+\*****************************************************************************/
+
+/* -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=- *\
+ | @file: $HeadURL: https://svn.bsc.es/repos/ptools/extrae/branches/2.3/src/merger/common/dump.c $
+ | @last_commit: $Date: 2013-02-27 11:43:34 +0100 (dc, 27 feb 2013) $
+ | @version:     $Revision: 1554 $
+\* -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=- */
+#include "common.h"
+
+static char UNUSED rcsid[] = "$Id: dump.c 1554 2013-02-27 10:43:34Z harald $";
+
+#ifdef HAVE_STDIO_H
+# include <stdio.h>
+#endif
+#ifdef HAVE_STDLIB_H
+# include <stdlib.h>
+#endif
+
+#include "options.h"
+#include "events.h"
+#include "record.h"
+#include "file_set.h"
+#include "HardwareCounters.h"
+
+#if USE_HARDWARE_COUNTERS
+static int num_counters = 0;
+#endif
+
+static void show_current (event_t * c, UINT64 max_time)
+{
+	int dump_time = get_option_dump_Time();
+
+	if (c->time < max_time) /* Check whether this event is back in time */
+	{
+		if (dump_time)
+#if SIZEOF_LONG == 8
+			fprintf (stdout, "TIME: %lu (delta = %lu) EV: %d VAL: %lu [0x%lx] ", c->time, max_time-c->time, c->event, c->value, c->value);
+		else
+			fprintf (stdout, "TIME: - (delta = -) EV: %d VAL: %lu [0x%lx] ", c->event, c->value, c->value);
+#else
+			fprintf (stdout, "TIME: %lu (delta = %lu) EV: %d VAL: %llu [0x%llx] ", c->time, max_time-c->time, c->event, c->value, c->value);
+		else
+			fprintf (stdout, "TIME: - (delta = -) EV: %d VAL: %llu [0x%llx] ", c->event, c->value, c->value);
+#endif
+	}
+	else 
+	{
+		char *clock_append = (c->time==max_time)?"+ ":"";
+
+		if (dump_time)
+#if SIZEOF_LONG == 8
+			fprintf (stdout, "TIME: %lu %s EV: %d VAL: %lu [0x%lx] ", c->time, clock_append, c->event, c->value, c->value);
+		else
+			fprintf (stdout, "TIME: - %s EV: %d VAL: %lu [0x%lx] ", clock_append, c->event, c->value, c->value);
+#else
+			fprintf (stdout, "TIME: %llu %s EV: %d VAL: %llu [0x%llx] ", c->time, clock_append, c->event, c->value, c->value);
+		else
+			fprintf (stdout, "TIME: - %s EV: %d VAL: %llu [0x%llx] ", clock_append, c->event, c->value, c->value);
+#endif
+	}
+
+	if (c->event == MPI_IRECV_EV || c->event == MPI_IRECVED_EV || c->event == MPI_RECV_EV ||
+	    c->event == MPI_SENDRECV_EV || c->event == MPI_SENDRECV_REPLACE_EV ||
+	    c->event == MPI_PERSIST_REQ_EV ||
+	    c->event == MPI_SEND_EV || c->event == MPI_ISEND_EV ||
+	    c->event == MPI_SSEND_EV || c->event == MPI_ISSEND_EV ||
+	    c->event == MPI_BSEND_EV || c->event == MPI_IBSEND_EV ||
+	    c->event == MPI_RSEND_EV || c->event == MPI_IRSEND_EV)
+	{
+		fprintf (stdout, "TARGET:%u SIZE:%d TAG:%d COMM:%d AUX:%lld\n",
+		  c->param.mpi_param.target,
+		  c->param.mpi_param.size, c->param.mpi_param.tag,
+		  c->param.mpi_param.comm, c->param.mpi_param.aux);
+	}
+	else if (c->event == USER_SEND_EV || c->event == USER_RECV_EV)
+	{
+		fprintf (stdout, "TARGET:%u SIZE:%d TAG:%d AUX:%lld\n",
+		  c->param.mpi_param.target, c->param.mpi_param.size,
+			c->param.mpi_param.tag, c->param.mpi_param.aux);
+	}
+	else if (c->event == MPI_COMM_SPLIT_EV || c->event == MPI_COMM_DUP_EV ||
+	         c->event == MPI_COMM_CREATE_EV || c->event == MPI_CART_CREATE_EV ||
+	         c->event == MPI_CART_SUB_EV)
+	{
+		fprintf (stdout, "COMM DEF SIZE: %d COMM: %d TRACE? %d\n",
+		  c->param.mpi_param.size, c->param.mpi_param.comm, c->param.mpi_param.aux);
+	}
+	else if (c->event == MPI_INIT_EV && c->value == EVT_END)
+	{
+		fprintf (stdout, "OPTIONS: 0x%08llx\n", c->param.mpi_param.aux);
+	}
+	else if (c->event == USER_EV)
+	{
+		fprintf (stdout, "USER EVENT value: %llu [0x%llx]\n", c->param.misc_param.param, c->param.misc_param.param);
+	}
+	else if (c->event == NAMEDCRIT_EV && (c->value == LOCK_VAL || c->value == UNLOCK_VAL))
+	{
+		fprintf (stdout, "NAMED CRITICAL ADDRESS: %llu [0x%llx]\n", c->param.omp_param.param, c->param.omp_param.param);
+	}
+#if USE_HARDWARE_COUNTERS
+	else if (c->event == HWC_DEF_EV)
+	{
+		int def_num_counters = 0;
+		int i;
+
+		fprintf (stdout, "HWC definition { ");
+		for (i = 0; i < MAX_HWC; i++)
+		{
+			fprintf (stdout, "0x%llx ", c->HWCValues[i]);
+			if (c->HWCValues[i] != NO_COUNTER)
+				def_num_counters++;
+		}
+		fprintf (stdout, "}\n");
+
+		num_counters = MAX (def_num_counters, num_counters);
+	}
+#endif
+  else
+    fprintf (stdout, "\n");
+
+#if USE_HARDWARE_COUNTERS
+  if (Get_EvHWCRead (c))
+		HardwareCounters_Show (c, num_counters);
+#endif
+}
+#if 0
+typedef struct
+{
+  u_param param;                 /* Parameters of this event              */
+  UINT64 value;                  /* Value of this event                   */
+  UINT64 time;                   /* Timestamp of this event               */
+#if 1 || USE_HARDWARE_COUNTERS || defined(HETEROGENEOUS_SUPPORT)
+  long long HWCValues[MAX_HWC];      /* Hardware counters read for this event */
+#endif
+  INT32 event;                   /* Type of this event                    */
+#if 1 || USE_HARDWARE_COUNTERS || defined(HETEROGENEOUS_SUPPORT)
+  INT32 HWCReadSet;              /* Marks which set of counters was read, if any */
+#endif
+} event_t;
+#endif
+
+
+void remap (FileSet_t *fset)
+{
+	UINT64 max_time;
+	UINT64 last_time;
+	unsigned i = 0;
+	event_t *e;
+
+	while (i < fset->nfiles)
+	{
+		last_time = max_time = 0;
+		fprintf (stdout, "File %d\n", i);
+		e = Current_FS (&fset->files[i]);
+		while (e != NULL)
+		{
+			if (Get_EvTime(e) < last_time)
+				fprintf (stdout, "** WARNING clock went backwards?\n");
+	
+			if(Get_EvEvent(e) == USER_SEND_EV || Get_EvEvent(e) == USER_RECV_EV)
+				show_current (e, max_time);
+
+			StepOne_FS (&fset->files[i]);
+			last_time = Get_EvTime(e);
+			max_time = MAX(Get_EvTime(e), max_time);
+			e = Current_FS (&fset->files[i]);
+		}
+		i++;
+	}
+	exit (0);
+}
+
diff -uNr extrae-2.3.4-vanilla/src/merger/common/hadoop_merge.h extrae-2.3.4-hadoop/src/merger/common/hadoop_merge.h
--- extrae-2.3.4-vanilla/src/merger/common/hadoop_merge.h	1970-01-01 01:00:00.000000000 +0100
+++ extrae-2.3.4-hadoop/src/merger/common/hadoop_merge.h	2013-09-08 23:56:42.541001318 +0200
@@ -0,0 +1,36 @@
+/*****************************************************************************\
+ *                        ANALYSIS PERFORMANCE TOOLS                         *
+ *                                   Extrae                                  *
+ *              Instrumentation package for parallel applications            *
+ *****************************************************************************
+ *     ___     This library is free software; you can redistribute it and/or *
+ *    /  __         modify it under the terms of the GNU LGPL as published   *
+ *   /  /  _____    by the Free Software Foundation; either version 2.1      *
+ *  /  /  /     \   of the License, or (at your option) any later version.   *
+ * (  (  ( B S C )                                                           *
+ *  \  \  \_____/   This library is distributed in hope that it will be      *
+ *   \  \__         useful but WITHOUT ANY WARRANTY; without even the        *
+ *    \___          implied warranty of MERCHANTABILITY or FITNESS FOR A     *
+ *                  PARTICULAR PURPOSE. See the GNU LGPL for more details.   *
+ *                                                                           *
+ * You should have received a copy of the GNU Lesser General Public License  *
+ * along with this library; if not, write to the Free Software Foundation,   *
+ * Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA          *
+ * The GNU LEsser General Public License is contained in the file COPYING.   *
+ *                                 ---------                                 *
+ *   Barcelona Supercomputing Center - Centro Nacional de Supercomputacion   *
+\*****************************************************************************/
+
+/* -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=- *\
+ | @file: $HeadURL: https://svn.bsc.es/repos/ptools/extrae/branches/2.3/src/merger/common/dump.h $
+ | @last_commit: $Date: 2010-10-26 14:58:30 +0200 (dt, 26 oct 2010) $
+ | @version:     $Revision: 476 $
+\* -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=- */
+
+#ifndef DUMP_H_INCLUDED
+#define DUMP_H_INCLUDED
+
+void remap (FileSet_t *fset);
+void hadoop_merge(int argc, char *argv[]);
+
+#endif /* DUMP_H_INCLUDED */
diff -uNr extrae-2.3.4-vanilla/src/merger/common/mpi2out.c extrae-2.3.4-hadoop/src/merger/common/mpi2out.c
--- extrae-2.3.4-vanilla/src/merger/common/mpi2out.c	2013-05-17 12:34:37.000000000 +0200
+++ extrae-2.3.4-hadoop/src/merger/common/mpi2out.c	2013-09-09 00:31:26.626284580 +0200
@@ -115,6 +115,7 @@
           "    -maxmem M Uses up to M megabytes of memory at the last step of merging process.\n"
           "    -dimemas  Force the generation of a Dimemas trace.\n"
           "    -paraver  Force the generation of a Paraver trace.\n"
+          "    -hadoop   HADOOP!!!.\n"
 #if defined(IS_BG_MACHINE)
           "    -xyzt     Generates additional output file with BG/L torus coordinates.\n"
 #endif
@@ -742,6 +743,12 @@
 			set_option_merge_ParaverFormat (TRUE);
 			continue;
 		}
+		if (!strcmp (argv[CurArg], "-hadoop"))
+		{
+			set_option_merge_ForceFormat (TRUE);
+			set_option_merge_ParaverHadoopFormat (TRUE);
+			continue;
+		}
 		if (!strcmp (argv[CurArg], "-skip-sendrecv"))
 		{
 			set_option_merge_SkipSendRecvComms (TRUE);
@@ -1186,9 +1193,14 @@
 		Labels_loadSYMfile (taskid, get_merge_SymbolFileName(), TRUE);
 
 	if (get_option_merge_ParaverFormat())
-		error = Paraver_ProcessTraceFiles (strip(get_merge_OutputTraceName()),
-			nTraces, InputTraces, get_option_merge_NumApplications(),
-			NodeCPUinfo, numtasks, taskid);
+		if(get_option_merge_ParaverHadoopFormat())
+			error = Hadoop_ProcessTraceFiles (strip(get_merge_OutputTraceName()),
+				nTraces, InputTraces, get_option_merge_NumApplications(),
+				NodeCPUinfo, numtasks, taskid);
+		else
+			error = Paraver_ProcessTraceFiles (strip(get_merge_OutputTraceName()),
+				nTraces, InputTraces, get_option_merge_NumApplications(),
+				NodeCPUinfo, numtasks, taskid);
 	else
 		error = Dimemas_ProcessTraceFiles (strip(get_merge_OutputTraceName()),
 			nTraces, InputTraces, get_option_merge_NumApplications(),
diff -uNr extrae-2.3.4-vanilla/src/merger/common/options.c extrae-2.3.4-hadoop/src/merger/common/options.c
--- extrae-2.3.4-vanilla/src/merger/common/options.c	2013-05-17 12:34:37.000000000 +0200
+++ extrae-2.3.4-hadoop/src/merger/common/options.c	2013-09-09 00:28:09.069275813 +0200
@@ -102,6 +102,10 @@
 int get_option_merge_ParaverFormat (void) { return option_merge_ParaverFormat; }
 void set_option_merge_ParaverFormat (int b) { option_merge_ParaverFormat = b; }
 
+static int option_merge_ParaverHadoopFormat = TRUE;
+int get_option_merge_ParaverHadoopFormat (void) { return option_merge_ParaverHadoopFormat; }
+void set_option_merge_ParaverHadoopFormat (int b) { option_merge_ParaverHadoopFormat = b; }
+
 static int option_merge_SortAddresses = TRUE;
 int get_option_merge_SortAddresses (void) { return option_merge_SortAddresses; }
 void set_option_merge_SortAddresses (int b) { option_merge_SortAddresses = b; }
diff -uNr extrae-2.3.4-vanilla/src/merger/common/options.h extrae-2.3.4-hadoop/src/merger/common/options.h
--- extrae-2.3.4-vanilla/src/merger/common/options.h	2013-05-17 12:34:37.000000000 +0200
+++ extrae-2.3.4-hadoop/src/merger/common/options.h	2013-09-09 00:27:32.115693848 +0200
@@ -84,6 +84,9 @@
 int get_option_merge_ParaverFormat (void);
 void set_option_merge_ParaverFormat (int b);
 
+int get_option_merge_ParaverHadoopFormat (void);
+void set_option_merge_ParaverHadoopFormat (int b);
+
 int get_option_merge_SortAddresses (void);
 void set_option_merge_SortAddresses (int b);
 
diff -uNr extrae-2.3.4-vanilla/src/merger/Makefile.am extrae-2.3.4-hadoop/src/merger/Makefile.am
--- extrae-2.3.4-vanilla/src/merger/Makefile.am	2013-05-17 12:34:37.000000000 +0200
+++ extrae-2.3.4-hadoop/src/merger/Makefile.am	2013-09-09 00:47:24.717530537 +0200
@@ -22,7 +22,8 @@
  common/semantics.c common/semantics.h \
  common/addresses.c common/addresses.h \
  common/vector.c common/vector.h \
- common/stack.c common/stack.h
+ common/stack.c common/stack.h \
+ common/hadoop_merge.c common/hadoop_merge.h
 
 dimemas_FILES = \
  dimemas/dimemas_generator.c dimemas/dimemas_generator.h \
diff -uNr extrae-2.3.4-vanilla/src/merger/Makefile.in extrae-2.3.4-hadoop/src/merger/Makefile.in
--- extrae-2.3.4-vanilla/src/merger/Makefile.in	2013-05-17 12:35:46.000000000 +0200
+++ extrae-2.3.4-hadoop/src/merger/Makefile.in	2013-09-09 00:47:59.494016617 +0200
@@ -111,7 +111,7 @@
 	libmpi2prv_la-mpi2out.lo libmpi2prv_la-options.lo \
 	libmpi2prv_la-object_tree.lo libmpi2prv_la-semantics.lo \
 	libmpi2prv_la-addresses.lo libmpi2prv_la-vector.lo \
-	libmpi2prv_la-stack.lo
+	libmpi2prv_la-stack.lo libmpi2prv_la-hadoop_merge.lo
 am_libmpi2prv_la_OBJECTS = libmpi2prv_la-addr2types.lo \
 	libmpi2prv_la-addr2info.lo \
 	libmpi2prv_la-addr2info_hashcache.lo libmpi2prv_la-file_set.lo \
@@ -536,7 +536,8 @@
  common/semantics.c common/semantics.h \
  common/addresses.c common/addresses.h \
  common/vector.c common/vector.h \
- common/stack.c common/stack.h
+ common/stack.c common/stack.h \
+ common/hadoop_merge.c common/hadoop_merge.h
 
 dimemas_FILES = \
  dimemas/dimemas_generator.c dimemas/dimemas_generator.h \
@@ -719,6 +720,7 @@
 @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/libmpi2prv_la-dimemas_generator.Plo@am__quote@
 @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/libmpi2prv_la-dump.Plo@am__quote@
 @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/libmpi2prv_la-file_set.Plo@am__quote@
+@AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/libmpi2prv_la-hadoop_merge.Plo@am__quote@
 @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/libmpi2prv_la-labels.Plo@am__quote@
 @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/libmpi2prv_la-misc_prv_events.Plo@am__quote@
 @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/libmpi2prv_la-misc_prv_semantics.Plo@am__quote@
@@ -1079,6 +1081,13 @@
 @AMDEP_TRUE@@am__fastdepCC_FALSE@	DEPDIR=$(DEPDIR) $(CCDEPMODE) $(depcomp) @AMDEPBACKSLASH@
 @am__fastdepCC_FALSE@	$(LIBTOOL)  --tag=CC $(AM_LIBTOOLFLAGS) $(LIBTOOLFLAGS) --mode=compile $(CC) $(DEFS) $(DEFAULT_INCLUDES) $(INCLUDES) $(AM_CPPFLAGS) $(CPPFLAGS) $(libmpi2prv_la_CFLAGS) $(CFLAGS) -c -o libmpi2prv_la-stack.lo `test -f 'common/stack.c' || echo '$(srcdir)/'`common/stack.c
 
+libmpi2prv_la-hadoop_merge.lo: common/hadoop_merge.c
+@am__fastdepCC_TRUE@	$(LIBTOOL)  --tag=CC $(AM_LIBTOOLFLAGS) $(LIBTOOLFLAGS) --mode=compile $(CC) $(DEFS) $(DEFAULT_INCLUDES) $(INCLUDES) $(AM_CPPFLAGS) $(CPPFLAGS) $(libmpi2prv_la_CFLAGS) $(CFLAGS) -MT libmpi2prv_la-hadoop_merge.lo -MD -MP -MF $(DEPDIR)/libmpi2prv_la-hadoop_merge.Tpo -c -o libmpi2prv_la-hadoop_merge.lo `test -f 'common/hadoop_merge.c' || echo '$(srcdir)/'`common/hadoop_merge.c
+@am__fastdepCC_TRUE@	$(am__mv) $(DEPDIR)/libmpi2prv_la-hadoop_merge.Tpo $(DEPDIR)/libmpi2prv_la-hadoop_merge.Plo
+@AMDEP_TRUE@@am__fastdepCC_FALSE@	source='common/hadoop_merge.c' object='libmpi2prv_la-hadoop_merge.lo' libtool=yes @AMDEPBACKSLASH@
+@AMDEP_TRUE@@am__fastdepCC_FALSE@	DEPDIR=$(DEPDIR) $(CCDEPMODE) $(depcomp) @AMDEPBACKSLASH@
+@am__fastdepCC_FALSE@	$(LIBTOOL)  --tag=CC $(AM_LIBTOOLFLAGS) $(LIBTOOLFLAGS) --mode=compile $(CC) $(DEFS) $(DEFAULT_INCLUDES) $(INCLUDES) $(AM_CPPFLAGS) $(CPPFLAGS) $(libmpi2prv_la_CFLAGS) $(CFLAGS) -c -o libmpi2prv_la-hadoop_merge.lo `test -f 'common/hadoop_merge.c' || echo '$(srcdir)/'`common/hadoop_merge.c
+
 mpi2prv-merger.o: merger.c
 @am__fastdepCC_TRUE@	$(CC) $(DEFS) $(DEFAULT_INCLUDES) $(INCLUDES) $(AM_CPPFLAGS) $(CPPFLAGS) $(mpi2prv_CFLAGS) $(CFLAGS) -MT mpi2prv-merger.o -MD -MP -MF $(DEPDIR)/mpi2prv-merger.Tpo -c -o mpi2prv-merger.o `test -f 'merger.c' || echo '$(srcdir)/'`merger.c
 @am__fastdepCC_TRUE@	$(am__mv) $(DEPDIR)/mpi2prv-merger.Tpo $(DEPDIR)/mpi2prv-merger.Po
diff -uNr extrae-2.3.4-vanilla/src/merger/paraver/trace_to_prv.c extrae-2.3.4-hadoop/src/merger/paraver/trace_to_prv.c
--- extrae-2.3.4-vanilla/src/merger/paraver/trace_to_prv.c	2013-05-17 12:34:37.000000000 +0200
+++ extrae-2.3.4-hadoop/src/merger/paraver/trace_to_prv.c	2013-09-09 00:34:50.684613606 +0200
@@ -621,3 +621,52 @@
 
 	return 0;
 }
+
+/******************************************************************************
+ ***  Hadoop_ProcessTraceFiles
+ ******************************************************************************/
+
+int Hadoop_ProcessTraceFiles (char *outName, unsigned long nfiles,
+	struct input_t *files, unsigned int num_appl,
+	struct Pair_NodeCPU *NodeCPUinfo, int numtasks, int taskid)
+{
+	struct timeval time_begin, time_end;
+	FileSet_t * fset;
+	unsigned int cpu, ptask, task, thread, error;
+	event_t * current_event;
+	char envName[PATH_MAX], *tmp;
+	unsigned int Type, EvType;
+	unsigned long long current_time = 0;
+	unsigned long long num_of_events, parsed_events, tmp_nevents;
+	unsigned long long records_per_task;
+	double pct, last_pct;
+	UINT64 *StartingTimes, *SynchronizationTimes;
+	int i;
+	long long options;
+	int num_appl_tasks[num_appl];
+
+	records_per_task = 1024*1024/sizeof(paraver_rec_t); /* num of events in 1 Mbytes */
+	records_per_task *= get_option_merge_MaxMem();            /* let's use this memory */
+
+	InitializeObjectTable (num_appl, files, nfiles);
+	for (i = 0; i < num_appl; i++)
+		num_appl_tasks[i] = (GET_PTASK_INFO(i+1))->ntasks;
+
+	Semantics_Initialize (PRV_SEMANTICS);
+
+	fset = Create_FS (nfiles, files, taskid, PRV_SEMANTICS);
+	error = (fset == NULL);
+
+
+	if (error)
+	{
+		if (0 == taskid)
+		{
+			fprintf (stderr, "mpi2prv: Error! Some of the processors failed create trace descriptors\n");
+			fflush (stderr);
+		}
+		return -1;
+	}
+
+	remap (fset);
+}
diff -uNr extrae-2.3.4-vanilla/src/merger/paraver/trace_to_prv.h extrae-2.3.4-hadoop/src/merger/paraver/trace_to_prv.h
--- extrae-2.3.4-vanilla/src/merger/paraver/trace_to_prv.h	2013-05-17 12:34:37.000000000 +0200
+++ extrae-2.3.4-hadoop/src/merger/paraver/trace_to_prv.h	2013-09-09 00:32:07.564978505 +0200
@@ -45,6 +45,10 @@
 	struct input_t *files, unsigned int num_appl,
 	struct Pair_NodeCPU *NodeCPUinfo, int numtasks, int idtask);
 
+int Hadoop_ProcessTraceFiles (char *prvName, unsigned long nfiles,
+	struct input_t *files, unsigned int num_appl,
+	struct Pair_NodeCPU *NodeCPUinfo, int numtasks, int idtask);
+
 extern int **EnabledTasks;
 extern unsigned long long **EnabledTasks_time;
 extern struct address_collector_t CollectedAddresses;
